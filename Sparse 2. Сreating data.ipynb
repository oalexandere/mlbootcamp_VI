{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "s\n",
    "def read_file(file_name, max_iters=float('Inf')):\n",
    "    data = []\n",
    "    n_items = 0\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        for row in f:\n",
    "            n_items += 1\n",
    "            data.append(row)\n",
    "            \n",
    "            if n_items > max_iters:\n",
    "                break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм формирования данных\n",
    "\n",
    "Из подготовленных текстовых файлов необходимо получить разреженные матрицы с помощью:\n",
    "- TfidfVectorizer для counters\n",
    "- CountVectorizer для остальных\n",
    "\n",
    "Полученные данные сохраняются отдельно для каждой категории признаков в npz. Для данных датасета (dataset) - train:\n",
    "- sp_train_counter.npz\n",
    "- sp_train_cat.npz\n",
    "- sp_train_day.npz\n",
    "- sp_train_day_cat.npz\n",
    "\n",
    "Аналогично для тестовой выборки:\n",
    "- sp_test_counter.npz\n",
    "- sp_test_cat.npz\n",
    "- sp_test_day.npz\n",
    "- sp_test_day_cat.npz\n",
    "\n",
    "\n",
    "##### Дополнительно создаются новые признаки комбинацией cat_feature и day_diff\n",
    "Полученные файлы:\n",
    "- sp_train_day_cat.npz\n",
    "- sp_test_day_cat.npz\n",
    "\n",
    "\n",
    "#### Все данные для train и test объединяются\n",
    "После онии используются при обучении финальной модели:\n",
    "- sp_train_dataset.npz\n",
    "- sp_test_dataset.npz\n",
    "\n",
    "#### Создание данных для валидации моделей\n",
    "Данные из файла sp_train_dataset.npz перемешиваются и разделяется с помощью StratifiedShuffleSplit:\n",
    "- sp_x_train_shuffled.npz\n",
    "- sp_x_valid_shuffled.npz\n",
    "- sp_y_train_shuffled.npz\n",
    "- sp_y_valid_shuffled.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method spmatrix.__str__ of <427994x793343 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 279184953 stored elements in Compressed Sparse Row format>>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'parse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parse' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_counter.csv')\n",
    "data = [x.rstrip('\\n') for x in data]\n",
    "\n",
    "transformer = TfidfVectorizer(min_df=3, max_df=0.4, sublinear_tf=True)\n",
    "\n",
    "data_out = transformer.fit_transform(data)\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_train_counter', data_out)\n",
    "print(data_out.__str__)\n",
    "\n",
    "del data, data_out\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Test\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_test_counter.csv')\n",
    "data = [x.rstrip('\\n') for x in data]\n",
    "\n",
    "data_out = transformer.transform(data)\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_test_counter', data_out)\n",
    "print(data_out.__str__)\n",
    "\n",
    "del data, data_out\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cat_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method spmatrix.__str__ of <427994x6 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 514272 stored elements in Compressed Sparse Row format>>\n",
      "<bound method spmatrix.__str__ of <181024x6 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 236723 stored elements in Compressed Sparse Row format>>\n",
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_cat.csv')\n",
    "\n",
    "# Удалить пробелы и спец символы\n",
    "data = [x.replace(' ', '').rstrip('\\n') for x in data]\n",
    "\n",
    "transformer = CountVectorizer(analyzer='char')\n",
    "# transformer = TfidfVectorizer(analyzer='char', use_idf=False)\n",
    "data_out = transformer.fit_transform(data)\n",
    "\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_train_cat', data_out)\n",
    "print(data_out.__str__)\n",
    "\n",
    "\n",
    "# Test\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_test_cat.csv')\n",
    "\n",
    "# Удалить пробелы и спец символы\n",
    "data = [x.replace(' ', '').rstrip('\\n') for x in data]\n",
    "data_out = transformer.transform(data)\n",
    "\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_test_cat', data_out)\n",
    "print(data_out.__str__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diff_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method spmatrix.__str__ of <427994x51 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 9683247 stored elements in Compressed Sparse Row format>>\n",
      "<bound method spmatrix.__str__ of <181024x51 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 4701874 stored elements in Compressed Sparse Row format>>\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_day.csv')\n",
    "\n",
    "# Удалить спец символы\n",
    "data = [x.rstrip('\\n') for x in data]\n",
    "\n",
    "transformer = CountVectorizer()\n",
    "# transformer = TfidfVectorizer(use_idf=False)\n",
    "data_out = transformer.fit_transform(data)\n",
    "print(data_out.__str__)\n",
    "\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_train_day', data_out)\n",
    "\n",
    "\n",
    "# Test\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_test_day.csv')\n",
    "\n",
    "# Удалить спец символы\n",
    "data = [x.rstrip('\\n') for x in data]\n",
    "\n",
    "data_out = transformer.transform(data)\n",
    "print(data_out.__str__)\n",
    "\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_test_day', data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание доп признаков вида day57_cat1\n",
    "\n",
    "Дополнительные признаки получены путем комбинации номеров дней и категориального признака cat_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для dataset\n",
    "\n",
    "cat_f = pd.read_csv('..\\\\sparse\\\\dataset_s_cat.csv', sep='\\t', header=None)[0].tolist()\n",
    "days = pd.read_csv('..\\\\sparse\\\\dataset_s_day.csv', sep='\\t', header=None)[0].tolist()\n",
    "\n",
    "new_feat = []\n",
    "for i in range(len(cat_f)):\n",
    "    new_feat.append(' '.join([f'day{d}_cat{c}' for d,c in zip(days[i].split(), cat_f[i].split())]))\n",
    "    \n",
    "pd.DataFrame(new_feat).to_csv('..\\\\sparse\\\\dataset_s_day_cat.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для dataset_test\n",
    "\n",
    "cat_f = pd.read_csv('..\\\\sparse\\\\dataset_s_test_cat.csv', sep='\\t', header=None)[0].tolist()\n",
    "days = pd.read_csv('..\\\\sparse\\\\dataset_s_test_day.csv', sep='\\t', header=None)[0].tolist()\n",
    "\n",
    "new_feat = []\n",
    "for i in range(len(cat_f)):\n",
    "    new_feat.append(' '.join([f'day{d}_cat{c}' for d,c in zip(days[i].split(), cat_f[i].split())]))\n",
    "\n",
    "pd.DataFrame(new_feat).to_csv('..\\\\sparse\\\\dataset_s_test_day_cat.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Датасет\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_day_cat.csv')\n",
    "data = [x.rstrip('\\n') for x in data]\n",
    "\n",
    "transformer = CountVectorizer()\n",
    "# transformer = TfidfVectorizer(use_idf=False)\n",
    "data_out = transformer.fit_transform(data)\n",
    "\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_train_day_cat', data_out)\n",
    "\n",
    "\n",
    "# Тестовая выборка\n",
    "data = read_file('..\\\\sparse\\\\dataset_s_test_day_cat.csv')\n",
    "data = [x.rstrip('\\n') for x in data]\n",
    "\n",
    "data_out = transformer.transform(data)\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_test_day_cat', data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение данных\n",
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method spmatrix.__str__ of <427994x793760 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 302256817 stored elements in COOrdinate format>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_counter = sparse.load_npz('..\\\\sparse\\\\sp_train_counter.npz')\n",
    "sp_cat = sparse.load_npz('..\\\\sparse\\\\sp_train_cat.npz')\n",
    "sp_day = sparse.load_npz('..\\\\sparse\\\\sp_train_day.npz')\n",
    "sp_day_cat = sparse.load_npz('..\\\\sparse\\\\sp_train_day_cat.npz')\n",
    "\n",
    "# Объединить данные\n",
    "X = sparse.hstack([sp_counter, sp_cat, sp_day, sp_day_cat])\n",
    "print(X.__str__)\n",
    "\n",
    "\n",
    "# Сохранить данные\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_train_dataset', X)\n",
    "\n",
    "del sp_counter, sp_cat, sp_day, sp_day_cat, X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method spmatrix.__str__ of <181024x793760 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 196816553 stored elements in COOrdinate format>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_test_counter = sparse.load_npz('..\\\\sparse\\\\sp_test_counter.npz')\n",
    "sp_test_cat = sparse.load_npz('..\\\\sparse\\\\sp_test_cat.npz')\n",
    "sp_test_day = sparse.load_npz('..\\\\sparse\\\\sp_test_day.npz')\n",
    "sp_test_day_cat = sparse.load_npz('..\\\\sparse\\\\sp_test_day_cat.npz')\n",
    "\n",
    "# Объединить данные\n",
    "X = sparse.hstack([sp_test_counter, sp_test_cat, sp_test_day, sp_test_day_cat])\n",
    "print(X.__str__)\n",
    "\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_test_dataset', X)\n",
    "\n",
    "del sp_test_counter, sp_test_cat, sp_test_day, sp_test_day_cat, X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перемешать и разделить train_dataset на train / valid\n",
    "\n",
    "Перемешать полученные данные и разделить их на тренировочную и валидационную выборку для дальнейшего подбора параметров моделей на валидации.\n",
    "\n",
    "Полученные файлы:\n",
    "- sp_x_train_shuffled.npz\n",
    "- sp_x_valid_shuffled.npz\n",
    "- sp_y_train_shuffled.npz\n",
    "- sp_y_valid_shuffled.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<427994x793760 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 302256817 stored elements in Compressed Sparse Row format>, (427994,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Датасет\n",
    "X_train = sparse.load_npz('..\\\\sparse\\\\sp_train_dataset.npz').tocsr()\n",
    "\n",
    "# Правильные ответы на train\n",
    "y_train = read_file('..\\\\sparse\\\\dataset_s_labels.csv')\n",
    "y_train = np.array([int(a) for a in y_train])\n",
    "\n",
    "X_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 55581 260848  35002 ... 292783 268123 310387] TEST: [ 23716  75326 408376 ... 102404 316201  86044]\n",
      "TRAIN len: 385194 TEST len: 42800\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.10, random_state=17)\n",
    "\n",
    "for train_index, valid_index in sss.split(X_train, y_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", valid_index)\n",
    "    print(\"TRAIN len:\", len(train_index), \"TEST len:\", len(valid_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('..\\\\sparse\\\\sp_x_train_shuffled', X_train[train_index])\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_x_valid_shuffled', X_train[valid_index])\n",
    "\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_y_train_shuffled', sparse.csr_matrix(y_train[train_index]))\n",
    "sparse.save_npz('..\\\\sparse\\\\sp_y_valid_shuffled', sparse.csr_matrix(y_train[valid_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
